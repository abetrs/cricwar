{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPL Transformer Model for Match Outcome Prediction\n",
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1: Imports and Setup ===\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../ipl_json\"\n",
    "SEQUENCE_LENGTH = 100\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_DIM = 64\n",
    "NUM_HEADS = 4\n",
    "NUM_LAYERS = 2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_deliveries(json_path):\n",
    "    deliveries = []\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        match = json.load(f)\n",
    "    for innings in match.get(\"innings\", []):\n",
    "        for over in innings.get(\"overs\", []):\n",
    "            over_num = over.get(\"over\", 0)\n",
    "            for delivery in over.get(\"deliveries\", []):\n",
    "                deliveries.append({\n",
    "                    'over': over_num,\n",
    "                    'batter': delivery.get(\"batter\"),\n",
    "                    'bowler': delivery.get(\"bowler\"),\n",
    "                    'runs': delivery.get(\"runs\", {}).get(\"total\", 0),\n",
    "                    'wicket': 1 if \"wickets\" in delivery else 0\n",
    "                })\n",
    "    return deliveries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [os.path.join(DATA_PATH, f) for f in os.listdir(DATA_PATH) if f.endswith(\".json\")]\n",
    "raw_data = []\n",
    "for f in all_files:\n",
    "    raw_data.extend(extract_deliveries(f))\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "batter_enc = LabelEncoder()\n",
    "bowler_enc = LabelEncoder()\n",
    "df['batter_id'] = batter_enc.fit_transform(df['batter'])\n",
    "df['bowler_id'] = bowler_enc.fit_transform(df['bowler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLDataset(Dataset):\n",
    "    def __init__(self, df, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        self.data = []\n",
    "        for i in range(len(df) - seq_len):\n",
    "            seq = df.iloc[i:i+seq_len]\n",
    "            x = seq[['batter_id', 'bowler_id', 'over', 'runs', 'wicket']].values\n",
    "            y = df.iloc[i+seq_len]['runs']\n",
    "            self.data.append((x, y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=num_heads)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(emb_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, features]\n",
    "        x = self.embed(x[:,:,0]) + self.embed(x[:,:,1])  # embed batter and bowler\n",
    "        x = x.permute(1, 0, 2)  # Transformer expects [seq_len, batch_size, emb_dim]\n",
    "        x = self.transformer(x)\n",
    "        out = self.fc(x[-1])\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhay\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = IPLDataset(df, SEQUENCE_LENGTH)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = IPLTransformer(vocab_size=len(batter_enc.classes_), emb_dim=EMBEDDING_DIM,\n",
    "                       num_heads=NUM_HEADS, num_layers=NUM_LAYERS).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 3.8633\n",
      "Epoch 2: Loss = 1.4995\n",
      "Epoch 3: Loss = 1.9061\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x, batch_y = batch_x.to(DEVICE), batch_y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(batch_x)\n",
    "        loss = criterion(preds, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoders.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"ipl_transformer.pt\")\n",
    "import joblib\n",
    "joblib.dump((batter_enc, bowler_enc), \"encoders.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy (1 - MAE / Mean Actual): -0.0939\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_runs</th>\n",
       "      <th>actual_runs</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   expected_runs  actual_runs  error\n",
       "0           0.83          1.0   0.17\n",
       "1           0.27          6.0   5.73\n",
       "2           0.40          0.0   0.40\n",
       "3          -0.42          0.0   0.42\n",
       "4           0.10          1.0   0.90\n",
       "5          -0.81          0.0   0.81\n",
       "6           0.01          0.0   0.01\n",
       "7           0.02          0.0   0.02\n",
       "8           0.14          0.0   0.14\n",
       "9           0.07          1.0   0.93"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "test_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x = batch_x.to(DEVICE)\n",
    "        preds = model(batch_x).cpu().numpy()\n",
    "        for i in range(len(preds)):\n",
    "            test_results.append({\n",
    "                'expected_runs': round(preds[i], 2),\n",
    "                'actual_runs': batch_y[i].item()\n",
    "            })\n",
    "\n",
    "# Create a DataFrame of predictions vs actuals\n",
    "log_df = pd.DataFrame(test_results)\n",
    "log_df['error'] = abs(log_df['expected_runs'] - log_df['actual_runs'])\n",
    "accuracy = 1 - (log_df['error'].mean() / (log_df['actual_runs'].mean() + 1e-6))\n",
    "\n",
    "print(f\"Model Accuracy (1 - MAE / Mean Actual): {accuracy:.4f}\")\n",
    "display(log_df.head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted runs for remaining balls: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Predicted final innings score: 154\n"
     ]
    }
   ],
   "source": [
    "# === CELL X: Load a Real Match and Simulate Prediction ===\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Step 1: Choose a real match JSON file from the folder\n",
    "json_files = [os.path.join(\"../ipl_json\", f) for f in os.listdir(\"../ipl_json\") if f.endswith(\".json\")]\n",
    "if not json_files:\n",
    "    raise Exception(\"No JSON files found in ../ipl_json\")\n",
    "\n",
    "# For this example, we use the first JSON file.\n",
    "match_file = json_files[0]\n",
    "\n",
    "# Use the provided extraction utility to get ball-by-ball deliveries\n",
    "match_deliveries = extract_deliveries(match_file)\n",
    "\n",
    "# Convert the list of deliveries to a DataFrame\n",
    "match_df = pd.DataFrame(match_deliveries)\n",
    "\n",
    "# For simulation purposes, we assume we're using data from one innings.\n",
    "# If your JSON contains multiple innings, you might want to filter for one.\n",
    "# (For example, you could select deliveries where over < some_threshold)\n",
    "\n",
    "# Ensure the match has at least SEQUENCE_LENGTH deliveries.\n",
    "if len(match_df) < SEQUENCE_LENGTH:\n",
    "    raise Exception(\"Not enough deliveries in this match for simulation.\")\n",
    "\n",
    "# Step 2: Encode the batter and bowler columns using the existing encoders.\n",
    "# (Assuming batter_enc and bowler_enc are already fit on a larger dataset.)\n",
    "match_df['batter_id'] = batter_enc.transform(match_df['batter'])\n",
    "match_df['bowler_id'] = bowler_enc.transform(match_df['bowler'])\n",
    "\n",
    "# Step 3: Prepare the seed sequence.\n",
    "# Here, we take the last SEQUENCE_LENGTH deliveries as the seed.\n",
    "seed_seq = match_df[['batter_id', 'bowler_id', 'over', 'runs', 'wicket']].values[-SEQUENCE_LENGTH:]\n",
    "\n",
    "# Determine the current state from the seed: using the last ball's info.\n",
    "batter_id = seed_seq[-1, 0]\n",
    "bowler_id = seed_seq[-1, 1]\n",
    "current_over = int(seed_seq[-1, 2])\n",
    "\n",
    "# For a T20 match, there are 120 balls in an innings.\n",
    "num_balls_remaining = 120 - SEQUENCE_LENGTH\n",
    "\n",
    "# Step 4: Define the simulation function (if not already defined)\n",
    "def simulate_innings(model, seed_seq, num_balls_remaining, batter_id, bowler_id, start_over):\n",
    "    \"\"\"\n",
    "    Simulates an innings by rolling the seed sequence forward, predicting each next ball.\n",
    "    \n",
    "    Parameters:\n",
    "      model: Trained Transformer model.\n",
    "      seed_seq: Numpy array of shape (seq_len, 5) containing the seed deliveries.\n",
    "      num_balls_remaining: Number of balls left to simulate.\n",
    "      batter_id: Batter identifier to use for simulated balls.\n",
    "      bowler_id: Bowler identifier to use for simulated balls.\n",
    "      start_over: Starting over number for the simulation.\n",
    "    \n",
    "    Returns:\n",
    "      predicted_runs: List of predicted runs for each simulated ball.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predicted_runs = []\n",
    "    # Copy the seed sequence to avoid modifying the original.\n",
    "    seq = seed_seq.copy()\n",
    "    current_over = start_over\n",
    "    ball_in_over = 0\n",
    "\n",
    "    for _ in range(num_balls_remaining):\n",
    "        # Prepare input with shape [1, seq_len, features]\n",
    "        input_seq = torch.tensor(seq, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            pred = model(input_seq).item()\n",
    "        # Round the prediction to the nearest integer (runs are discrete)\n",
    "        run = int(round(pred))\n",
    "        predicted_runs.append(run)\n",
    "        \n",
    "        # Create a new ball record:\n",
    "        # Using the same batter_id and bowler_id for simplicity,\n",
    "        # the current over, predicted run, and wicket set to 0.\n",
    "        new_ball = [batter_id, bowler_id, current_over, run, 0]\n",
    "        \n",
    "        # Slide the window: remove the first ball and append the new one.\n",
    "        seq = np.vstack([seq[1:], new_ball])\n",
    "        \n",
    "        ball_in_over += 1\n",
    "        if ball_in_over == 6:\n",
    "            ball_in_over = 0\n",
    "            current_over += 1\n",
    "\n",
    "    return predicted_runs\n",
    "\n",
    "# Step 5: Generate predictions for the remaining balls.\n",
    "predicted_remaining_runs = simulate_innings(model, seed_seq, num_balls_remaining, batter_id, bowler_id, current_over)\n",
    "\n",
    "# Step 6: Compute the predicted final innings score.\n",
    "# We assume the seed sequence represents the score so far.\n",
    "seed_runs = seed_seq[:, 3].sum()  # Sum of runs in the seed sequence\n",
    "predicted_total_score = seed_runs + sum(predicted_remaining_runs)\n",
    "\n",
    "print(\"Predicted runs for remaining balls:\", predicted_remaining_runs)\n",
    "print(\"Predicted final innings score:\", predicted_total_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
